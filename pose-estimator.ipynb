{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaec96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook includes the necessary components to train stage one of the deep pose model\n",
    "# You can choose to either download the dataset from google drive in the cells below or create the dataset yourself\n",
    "# Using the dataset generator notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad33365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from google drive\n",
    "# !gdown https://drive.google.com/uc?id=1ioRIMhfxZCKGvXI6j-69S-qJ20NFXE4n\n",
    "\n",
    "# Otherwise run dataset-generator.ipynb to create dataset\n",
    "\n",
    "# !unzip -q data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image\n",
    "from matplotlib import patches\n",
    "import zipfile\n",
    "from pycocotools.coco import COCO\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random as rn\n",
    "from datetime import datetime\n",
    "import ipywidgets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb77818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data frames\n",
    "train_df = pd.read_pickle('train_df.pkl')\n",
    "val_df = pd.read_pickle('val_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix val_df set keypoints to 0 if v is 0\n",
    "drop = []\n",
    "for row in range(len(train_df)):\n",
    "    keypoints = train_df.iloc[row]['keypoints']\n",
    "    if 'c' in train_df.iloc[row]['path']:\n",
    "        drop.append(row)\n",
    "        continue\n",
    "    \n",
    "    # Add 0.5 to all keypoints as they were normalized between -0.5 to 0.5\n",
    "    keypoints = keypoints.reshape(-1, 3)\n",
    "    keypoints[:,0:2] += 0.5\n",
    "    \n",
    "    # If x == 0 or y == 0 or v == 0 set x,y,v to 0\n",
    "    v_0_indices = np.where((keypoints[:,2] == 0))[0]\n",
    "    y_0_indices = np.where((keypoints[:,1] == 0))[0]\n",
    "    x_0_indices = np.where((keypoints[:,0] == 0))[0]\n",
    "    keypoints[v_0_indices] = [0,0,0]\n",
    "    keypoints[y_0_indices] = [0,0,0]\n",
    "    keypoints[x_0_indices] = [0,0,0]\n",
    "    \n",
    "    keypoints = keypoints.reshape(-1)\n",
    "\n",
    "    # Drop rows with 5 or less keypoints\n",
    "    if len(v_0_indices.reshape(-1)) > 5:\n",
    "        drop.append(row)\n",
    "    else:\n",
    "        train_df.at[row, 'keypoints'] = keypoints\n",
    "\n",
    "train_df = train_df.drop(drop)\n",
    "\n",
    "# Fix val_df set keypoints to 0 if v is 0\n",
    "drop = []\n",
    "for row in range(len(val_df)):\n",
    "    keypoints = val_df.iloc[row]['keypoints']\n",
    "    if 'c' in val_df.iloc[row]['path']:\n",
    "        drop.append(row)\n",
    "        continue\n",
    "    \n",
    "    # Add 0.5 to all kps\n",
    "    keypoints = keypoints.reshape(-1, 3)\n",
    "    keypoints[:,0:2] += 0.5\n",
    "    \n",
    "    # If x == 0 or y == 0 or v == 0 set x,y,v to 0\n",
    "    v_0_indices = np.where((keypoints[:,2] == 0))[0]\n",
    "    y_0_indices = np.where((keypoints[:,1] == 0))[0]\n",
    "    x_0_indices = np.where((keypoints[:,0] == 0))[0]\n",
    "    keypoints[v_0_indices] = [0,0,0]\n",
    "    keypoints[y_0_indices] = [0,0,0]\n",
    "    keypoints[x_0_indices] = [0,0,0]\n",
    "    \n",
    "    keypoints = keypoints.reshape(-1)\n",
    "    \n",
    "    # Drop rows with 5 or less keypoints\n",
    "\n",
    "    if len(v_0_indices.reshape(-1)) > 5:\n",
    "        drop.append(row)\n",
    "    else:\n",
    "        val_df.at[row, 'keypoints'] = keypoints\n",
    "        \n",
    "val_df = val_df.drop(drop)\n",
    "\n",
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa355567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a CxHxW image with keypoints and displays it with keypoints\n",
    "def displayImageWithKeyPointsOld(img, keypoints, ax=None, show=True):\n",
    "    colors = ['red', 'blue', 'magenta', 'lime', 'orange', 'purple', 'pink', 'yellow', 'aqua', 'fuchsia', 'azure', 'lavender', 'magenta', 'white', 'sienna', 'indigo', 'coral']\n",
    "    img = np.swapaxes(img,0,2)\n",
    "    img = np.swapaxes(img,0,1)\n",
    "\n",
    "    #fig = None\n",
    "    if(ax is None):\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    w = img.shape[1]\n",
    "    h = img.shape[0]\n",
    "    \n",
    "    # Show kps\n",
    "    for i in range(2, len(keypoints), 3):\n",
    "        x = keypoints[i-2]\n",
    "        y = keypoints[i-1]\n",
    "        v = keypoints[i]\n",
    "        \n",
    "        x = (x)*w\n",
    "        y = (y)*h\n",
    "        if v == 0: continue\n",
    "        \n",
    "        ax.plot(x, y, marker='x', color=colors[i//3])\n",
    "    if(show):\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_names = [ \"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\", \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \n",
    "    \"right_elbow\", \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\", \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\" ]\n",
    "\n",
    "kp_dict = {name:i*3 for i, name in enumerate(kp_names)}\n",
    "print(kp_dict)\n",
    "\n",
    "# Takes in a CXHXW image with keypoints and displays it with keypoints\n",
    "def displayImageWithKeyPoints(img, keypoints, ax=None, show=True):\n",
    "    img = np.swapaxes(img,0,2)\n",
    "    img = np.swapaxes(img,0,1)\n",
    "\n",
    "    #fig = None\n",
    "    if(ax is None):\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    w = img.shape[1]\n",
    "    h = img.shape[0]\n",
    "    \n",
    "    # Show kps\n",
    "    \n",
    "    for i in range(2, len(keypoints), 3):\n",
    "        if(i > 1 and i < 10): \n",
    "            continue\n",
    "        x = keypoints[i-2]\n",
    "        y = keypoints[i-1]\n",
    "        v = keypoints[i]\n",
    "        x = (x)*w\n",
    "        y = (y)*h\n",
    "        if v < 0.7: continue\n",
    "        ax.plot(x, y, marker='o', color='black')\n",
    "\n",
    "    # draw skeleton\n",
    "    left_arm = [\"left_shoulder\", \"left_elbow\", \"left_wrist\"]\n",
    "    right_arm = [\"right_shoulder\", \"right_elbow\", \"right_wrist\"]\n",
    "    left_leg = [\"left_hip\", \"left_knee\", \"left_ankle\"]\n",
    "    right_leg = [\"right_hip\", \"right_knee\", \"right_ankle\"]\n",
    "\n",
    "    bones = [left_arm, right_arm, left_leg, right_leg]\n",
    "    colors = ['red', 'blue', 'green', 'yellow']\n",
    "\n",
    "    for i, bone in enumerate(bones):\n",
    "        x_l = []\n",
    "        y_l = []\n",
    "        for keypoint in bone:\n",
    "            idx = kp_dict[keypoint]\n",
    "            x = keypoints[idx]*w\n",
    "            y = keypoints[idx+1]*h\n",
    "            if x < 0 or y == 0: continue\n",
    "            x_l.append(x)\n",
    "            y_l.append(y)\n",
    "        \n",
    "        ax.plot(x_l, y_l, color=colors[i], linewidth=2)\n",
    "    \n",
    "    # torso:\n",
    "    torso_upper_x = (keypoints[kp_dict[\"left_shoulder\"]] + keypoints[kp_dict[\"right_shoulder\"]])/2 * w\n",
    "    torso_upper_y = (keypoints[kp_dict[\"left_shoulder\"]+1] + keypoints[kp_dict[\"right_shoulder\"]+1])/2 * h\n",
    "    torso_lower_x = (keypoints[kp_dict[\"left_hip\"]] + keypoints[kp_dict[\"right_hip\"]])/2 * w\n",
    "    torso_lower_y = (keypoints[kp_dict[\"left_hip\"]+1] + keypoints[kp_dict[\"right_hip\"]+1])/2 * h\n",
    "    torso_x = [torso_upper_x, torso_lower_x]\n",
    "    torso_y = [torso_upper_y, torso_lower_y]\n",
    "    ax.plot(torso_x, torso_y, color='magenta', linewidth=2)\n",
    "\n",
    "    # connectors \n",
    "    face_c_x = [torso_upper_x, keypoints[kp_dict[\"nose\"]]*w]\n",
    "    face_c_y = [torso_upper_y, keypoints[kp_dict[\"nose\"]+1]*h]\n",
    "    if 0 not in face_c_x and 0 not in face_c_y: ax.plot(face_c_x, face_c_y, color='white', linewidth=2)\n",
    "\n",
    "    upleft_c_x = [torso_upper_x, keypoints[kp_dict[\"left_shoulder\"]]*w]\n",
    "    upleft_c_y = [torso_upper_y, keypoints[kp_dict[\"left_shoulder\"]+1]*h]\n",
    "    if 0 not in upleft_c_x and 0 not in upleft_c_y: ax.plot(upleft_c_x, upleft_c_y, color='white', linewidth=2)\n",
    "\n",
    "    upleft_c_x = [torso_upper_x, keypoints[kp_dict[\"right_shoulder\"]]*w]\n",
    "    upleft_c_y = [torso_upper_y, keypoints[kp_dict[\"right_shoulder\"]+1]*h]\n",
    "    if 0 not in upleft_c_x and 0 not in upleft_c_y: ax.plot(upleft_c_x, upleft_c_y, color='white', linewidth=2)\n",
    "\n",
    "    upleft_c_x = [torso_lower_x, keypoints[kp_dict[\"left_hip\"]]*w]\n",
    "    upleft_c_y = [torso_lower_y, keypoints[kp_dict[\"left_hip\"]+1]*h]\n",
    "    if 0 not in upleft_c_x and 0 not in upleft_c_y: ax.plot(upleft_c_x, upleft_c_y, color='white', linewidth=2)\n",
    "\n",
    "    upleft_c_x = [torso_lower_x, keypoints[kp_dict[\"right_hip\"]]*w]\n",
    "    upleft_c_y = [torso_lower_y, keypoints[kp_dict[\"right_hip\"]+1]*h]\n",
    "    if 0 not in upleft_c_x and 0 not in upleft_c_y: ax.plot(upleft_c_x, upleft_c_y, color='white', linewidth=2)\n",
    "\n",
    "    if(show):\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for training and validation\n",
    "class Coco(Dataset):\n",
    "    def __init__(self, df, source, dimensions, transform=None):\n",
    "        super().__init__()\n",
    "        # Dataframe of annotations\n",
    "        self.df = df\n",
    "        # Either train or val to indicate set\n",
    "        self.source = source\n",
    "        # Square dimensions of image\n",
    "        self.dimensions = dimensions\n",
    "        # transform\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get data\n",
    "        img = image.imread(f'{self.source}2017/{self.df.iloc[index][\"path\"]}')\n",
    "        \n",
    "        # Apply transforms to image\n",
    "        if self.transform: img = self.transform(img)\n",
    "        \n",
    "        # Return data\n",
    "        return img, torch.FloatTensor(self.df.iloc[index][\"keypoints\"])#.reshape(-1, 3)[:, 0:2].reshape(-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data loader and print an image with keypoints\n",
    "composed_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ColorJitter(brightness=.3, hue=0.2),\n",
    "    transforms.RandomPosterize(bits=6),\n",
    "    transforms.RandomSolarize(245, p=0.05),\n",
    "    transforms.RandomAdjustSharpness(5, p=0.2),\n",
    "    transforms.RandomAutocontrast(),\n",
    "    transforms.RandomEqualize(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=Coco(train_df, 'train', 224, transform=composed_transforms),\n",
    "    batch_size=1, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "# Example from data loader after normalization\n",
    "img, labels = iter(train_dataloader).next()\n",
    "a = img[0].numpy()\n",
    "b = (a - np.min(a))/np.ptp(a)\n",
    "displayImageWithKeyPoints(b, labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network\n",
    "# Switch to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9738ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = Coco(train_df, 'train', 224, transform=composed_transforms)\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "val_dataset = Coco(val_df, 'val', 224, transform=composed_transforms)\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b1718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss_masked(output, target):\n",
    "    out = output.reshape(-1, 3)\n",
    "    tar = target.reshape(-1, 3)\n",
    "    \n",
    "    not_present_tar_indices = torch.where((tar[:,2] == 0))[0]\n",
    "    mask = torch.ones_like(out).to(device)\n",
    "    mask[not_present_tar_indices] = torch.tensor([0.,0.,1]).to(device)\n",
    "    \n",
    "    return torch.sum(mask*(out - tar)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27edbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define accuracy checking step\n",
    "def check_validation_accuracy(model):\n",
    "    criterion = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        for i, data in enumerate(val_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # get predictions\n",
    "            outputs = model(inputs)\n",
    "            loss += l2_loss_masked(outputs, labels).item()\n",
    "\n",
    "        print(f\"Validiation loss was {loss}\")\n",
    "    \n",
    "    # visualize some random gt vs prediction\n",
    "    idx = rn.randint(0, 100)\n",
    "    img, labels = val_dataset[idx]\n",
    "    a = img.numpy()\n",
    "    b = (a - np.min(a))/np.ptp(a)\n",
    "    \n",
    "    img = img.to(device)\n",
    "    outputs = model(img.unsqueeze(0))\n",
    "    outputs = outputs.to('cpu')\n",
    "\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "    displayImageWithKeyPoints(b, labels, ax0, False)\n",
    "    displayImageWithKeyPoints(b, outputs[0].detach().numpy(), ax1, True)\n",
    "\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, val_nodecrease_cutoff):\n",
    "    criterion = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.0009, lr_decay=0, weight_decay=0.01, initial_accumulator_value=0, eps=1e-10)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.75)\n",
    "\n",
    "    print(f\"Training {epochs} epochs. Dataset is {len(train_dataset)} big. Using batch size {batch_size}\")\n",
    "    print(f\"{len(train_dataset) // batch_size + 1} minibatches are needed per epoch\")\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    min_val_loss = (0, 9999999999999)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = l2_loss_masked(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 250 == 0:\n",
    "                print(f\"Minibatch {i+1}/{len(train_dataset)//batch_size+1}. Loss {loss.item()}\")\n",
    "\n",
    "        running_loss = running_loss / len(train_df)\n",
    "        scheduler.step()\n",
    "\n",
    "        # print statistics\n",
    "        print(f'Epoch {epoch}/{epochs}. Loss {running_loss}. {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "        print(len(train_df))\n",
    "\n",
    "        # Store losses\n",
    "        train_loss_history.append(running_loss)\n",
    "        val_loss = check_validation_accuracy(model) / len(val_df)\n",
    "        val_loss_history.append(val_loss)\n",
    "        \n",
    "        np.save('train_history.npy', np.array(train_loss_history))\n",
    "        np.save('val_history.npy', np.array(val_loss_history))\n",
    "\n",
    "        # Save model if loss low\n",
    "        if val_loss < min_val_loss[1]:\n",
    "            min_val_loss = (epoch, val_loss)\n",
    "            torch.save(model.state_dict(), 'model.pth')\n",
    "            \n",
    "        # Check if we should stop training because val loss not decreasing\n",
    "        if epoch - min_val_loss[0] > val_nodecrease_cutoff:\n",
    "            break\n",
    "    \n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 96, kernel_size=(11, 11), stride=(4,4), padding=(5,5)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(96),\n",
    "\n",
    "    torch.nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "\n",
    "    torch.nn.Conv2d(96, 256, kernel_size=(5, 5), padding=(2,2)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(256),\n",
    "\n",
    "    torch.nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "\n",
    "    torch.nn.Conv2d(256, 384, kernel_size=(3, 3), padding=(1,1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(384),\n",
    "\n",
    "    torch.nn.Conv2d(384, 384, kernel_size=(3, 3), padding=(1,1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(384),\n",
    "\n",
    "    torch.nn.Conv2d(384, 256, kernel_size=(3, 3), padding=(1,1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(256),\n",
    "\n",
    "    torch.nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "    torch.nn.Flatten(),\n",
    "\n",
    "    torch.nn.Linear(12544, 4096),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(p=0.4),\n",
    "\n",
    "    torch.nn.Linear(4096, 4096),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(p=0.4),\n",
    "\n",
    "    torch.nn.Linear(4096, 51),\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if present\n",
    "model.load_state_dict(torch.load(\"model_v.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef275a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history, val_loss_history = train(model, 500, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acfb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training stats\n",
    "plt.plot(val_loss_history, label=\"Validation\")\n",
    "plt.plot(train_loss_history, label=\"Training\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
